{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_from_scratch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asafe-eduardo/colab/blob/master/rnn_from_scratch/lstm_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNAjZK1jEH6f",
        "colab_type": "text"
      },
      "source": [
        "### IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlO_Z7sjjrfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np #for maths\n",
        "import pandas as pd #for data manipulation\n",
        "import matplotlib.pyplot as plt #for visualization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5otaaPc7EQq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data\n",
        "path = 'NationalNames.csv'\n",
        "data = pd.read_csv(path)\n",
        "\n",
        "data = np.array(data['Name'][:10000]).reshape(-1, 1)\n",
        "\n",
        "data = [x.lower() for x in data[:,0]]\n",
        "\n",
        "data = np.array(data).reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXJMqAvgM3NW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f911713f-afc0-43f0-dfca-889ab1d9788e"
      },
      "source": [
        "print(\"Data Shape = {}\".format(data.shape) + \"\\n\")\n",
        "print(\"Lets see some names: \")\n",
        "print(data[1:10])"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape = (10000, 1)\n",
            "\n",
            "Lets see some names: \n",
            "[['anna']\n",
            " ['emma']\n",
            " ['elizabeth']\n",
            " ['minnie']\n",
            " ['margaret']\n",
            " ['ida']\n",
            " ['alice']\n",
            " ['bertha']\n",
            " ['sarah']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqq5LNZSNLHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_data = np.copy(data)\n",
        "\n",
        "max_length = 0\n",
        "for index in range(len(data)):\n",
        "  max_length = max(max_length, len(data[index, 0]))\n",
        "  \n",
        "for index in range(len(data)):\n",
        "  length = (max_length - len(data[index, 0]))\n",
        "  string = '.'*length\n",
        "  transform_data[index,0] = '.'.join([transform_data[index, 0], string])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0uvJYq4N1DR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e1610504-a26c-4e19-aa65-8f3bb0914018"
      },
      "source": [
        "print(\"Transformed Data\")\n",
        "print(transform_data[1:10])"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transformed Data\n",
            "[['anna........']\n",
            " ['emma........']\n",
            " ['elizabeth...']\n",
            " ['minnie......']\n",
            " ['margaret....']\n",
            " ['ida.........']\n",
            " ['alice.......']\n",
            " ['bertha......']\n",
            " ['sarah.......']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yXfU67yOGt-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9e512dda-9081-4168-a127-ce9e00718c34"
      },
      "source": [
        "vocab = list()\n",
        "for name in transform_data[:,0]:\n",
        "  vocab.extend(list(name))\n",
        "  \n",
        "vocab = set(vocab)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "print(\"Vocab size = {}\".format(len(vocab)))\n",
        "print(\"Vocab      = {}\".format(vocab))"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size = 27\n",
            "Vocab      = set(['.', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'j', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SCMpoq1OimB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30a71aa7-9908-4ccb-f8dc-e8652abd515d"
      },
      "source": [
        "char_id = dict()\n",
        "id_char = dict()\n",
        "\n",
        "for i, char in enumerate(vocab):\n",
        "  char_id[char] = i\n",
        "  id_char[i] = char\n",
        "  \n",
        "print('a-{}, 22-{}'.format(char_id['a'], id_char[22]))"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a-1, 22-w\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8JEXc0GQJcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = []\n",
        "\n",
        "batch_size = 20\n",
        "\n",
        "for i in range(len(transform_data) - batch_size+1):\n",
        "  start = i*batch_size\n",
        "  end = start+batch_size\n",
        "  \n",
        "  batch_data = transform_data[start:end]\n",
        "  \n",
        "  if(len(batch_data) != batch_size):\n",
        "    break\n",
        "  \n",
        "  char_list = []\n",
        "  \n",
        "  for k in range(len(batch_data[0][0])):\n",
        "    batch_dataset = np.zeros([batch_size, len(vocab)])\n",
        "    for j in range(batch_size):\n",
        "      name = batch_data[j][0]\n",
        "      char_index = char_id[name[k]]\n",
        "      batch_dataset[j, char_index] = 1.0\n",
        "      \n",
        "    char_list.append(batch_dataset)\n",
        "    \n",
        "  train_dataset.append(char_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0cJnEn_RlA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_units = 100\n",
        "\n",
        "hidden_units = 256\n",
        "\n",
        "output_units = vocab_size\n",
        "\n",
        "learning_rate = 0.005\n",
        "\n",
        "beta1 = 0.90\n",
        "beta2 = 0.99"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UezubSXYSRAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(X):\n",
        "  return 1/(1+np.exp(-X))\n",
        "\n",
        "def tanh_activation(X):\n",
        "  return np.tanh(X)\n",
        "\n",
        "def softmax(X):\n",
        "  exp_X = np.exp(X)\n",
        "  exp_X_sum = np.sum(exp_X, axis=1).reshape(-1, 1)\n",
        "  exp_X = exp_X/exp_X_sum\n",
        "  return exp_X\n",
        "\n",
        "def tanh_derivative(X):\n",
        "  return 1-(X**2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjQwiahwUsA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters():\n",
        "  mean = 0\n",
        "  std = 0.01\n",
        "  \n",
        "  forget_gate_weights = np.random.normal(mean, std, (input_units + hidden_units, hidden_units))\n",
        "  input_gate_weights = np.random.normal(mean, std, (input_units + hidden_units, hidden_units))\n",
        "  output_gate_weights = np.random.normal(mean, std, (input_units + hidden_units, hidden_units))\n",
        "  gate_gate_weights = np.random.normal(mean, std, (input_units + hidden_units, hidden_units))\n",
        "  \n",
        "  hidden_output_weights = np.random.normal(mean, std, (hidden_units, output_units))\n",
        "  \n",
        "  parameters = dict()\n",
        "  parameters['fgw'] = forget_gate_weights\n",
        "  parameters['igw'] = input_gate_weights\n",
        "  parameters['ogw'] = output_gate_weights\n",
        "  parameters['ggw'] = gate_gate_weights\n",
        "  parameters['how'] = hidden_output_weights\n",
        "  \n",
        "  return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkL4jUSJW7LX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm_cell(batch_dataset, prev_activation_matrix, prev_cell_matrix, parameters):\n",
        "  fgw = parameters['fgw']\n",
        "  igw = parameters['igw']\n",
        "  ogw = parameters['ogw']\n",
        "  ggw = parameters['ggw']\n",
        "  \n",
        "  concat_dataset = np.concatenate((batch_dataset, prev_activation_matrix), axis=1)\n",
        "  \n",
        "  fa = np.matmul(concat_dataset, fgw)\n",
        "  fa = sigmoid(fa)\n",
        "  \n",
        "  ia = np.matmul(concat_dataset, igw)\n",
        "  ia = sigmoid(ia)\n",
        "  \n",
        "  oa = np.matmul(concat_dataset, ogw)\n",
        "  oa = sigmoid(oa)\n",
        "  \n",
        "  ga = np.matmul(concat_dataset, ggw)\n",
        "  ga = tahn_activation(ga)\n",
        "  \n",
        "  cell_memory_matrix = np.multiply(fa,prev_cell_matrix) + np.multiply(ia, ga)\n",
        "  \n",
        "  activation_matrix = np.multiply(oa, tanh_activation(cell_memory_matrix))\n",
        "  \n",
        "  lstm_activation = dict()\n",
        "  lstm_activation['fa'] = fa\n",
        "  lstm_activation['ia'] = ia\n",
        "  lstm_activation['oa'] = oa\n",
        "  lstm_activation['ga'] = ga\n",
        "  \n",
        "  return lstm_activation,cell_memory_matrix,activation_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyWpiUkeYaUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_cell(activation_matrix, parameters):\n",
        "  how = parameters['how']\n",
        "  \n",
        "  output_matrix = np.matmul(activation_matrix, how)\n",
        "  output_matrix = softmax(output_matrix)\n",
        "  \n",
        "  return output_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGo0XKufY-kF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(batch_dataset, embeddings):\n",
        "  embedding_dataset = np.matmul(batch_daset, embeddings)\n",
        "  return embedding_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMadxYDeeHX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_propagation(batches, parameters, embeddings):\n",
        "  batch_size = batches[0].shape[0]\n",
        "  \n",
        "  lstm_cache = dict()\n",
        "  activation_cache = dict()\n",
        "  cell_cache = dict()\n",
        "  output_cache = dict()\n",
        "  embedding_cache = dict()\n",
        "  \n",
        "  a0 = np.zeros([batch_size, hidden_units], dtype=np.float32)\n",
        "  c0 = np.zeros([batch_size, hidden_units], dtype=np.float32)\n",
        "  \n",
        "  actiation_cache['a0'] = a0\n",
        "  cell_cache['c0'] = c0\n",
        "  \n",
        "  for i in range(len(batches) - 1):\n",
        "    batch_dataset = batches[i]\n",
        "    \n",
        "    batch_dataset = get_embeddings(batch_dataset, embeddings)\n",
        "    embedding_cache['emb' + str(i)] = batch_dataset\n",
        "    \n",
        "    lstm_activation, ct, at = lstm_cell(batch_dataset, a0, c0, parameters)\n",
        "    \n",
        "    ot = output_cell(at, parameters)\n",
        "    \n",
        "    lstm_cache['lstm' + str(i+1)] = lstm_activations\n",
        "    activation_cache['a'+str(i+1)] = at\n",
        "    cell_cache['c' + str(i+1)] = ct\n",
        "    output_cache['o'+str(i+1)] = ot\n",
        "    \n",
        "    a0 = at\n",
        "    c0 = ct\n",
        "    \n",
        "    return embedding,cache, lst_cache, activation_cache, cell_cache, output_cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "523ejks9fw_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_loss_accuracy(batch_labels, output_cache):\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  prob = 1\n",
        "  \n",
        "  batch_size = batch_labels[0].shape[0]\n",
        "  \n",
        "  for i in range(1, len(output_cache) + 1):\n",
        "    labels = batch_labels[i]\n",
        "    pred = output_cache['0'+str(i)]\n",
        "    \n",
        "    prob = np.multiply(prob, np.sum(np.multiply(labels, pred), axis=1).reshape(-1, 1))\n",
        "    loss += np.sum((np.multiply(labels, np.log(pred)) + np.multiply(1 - labels, np.log(1-pred))), axis=1).reshape\n",
        "    acc += np.array(np.argmax(labels, 1) == np.argmax(pred, 1), dtype=np.float32).reshape(-1, 1)\n",
        "    \n",
        "    perplexity = np.sum((1/prob) ** (1/len(output_cache)))/batch_size\n",
        "    loss = np.sum(loss)*np(-1/batch_size)\n",
        "    acc = np.sum(acc)/(batch_size)\n",
        "    acc = acc/len(output_cache)\n",
        "    return perplexity, loss, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ08hBN4hQj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_output_cell_error(batch_labels, output_cache, parameters):\n",
        "  output_error_cache = dict()\n",
        "  activation_error_cache = dict()\n",
        "  how = parameters['how']\n",
        "  \n",
        "  for i in rnage(1, len(output_cache) +1):\n",
        "    labels = batch_labels[i]\n",
        "    pred = output_cache['o'+ str(i)]\n",
        "    \n",
        "    error_output = pred - labels\n",
        "    \n",
        "    error_activation = np.matmul(error_output, how.T)\n",
        "    \n",
        "    output_error_cache['eo'+str(i)] = error_output\n",
        "    activation_error_cache['ea'+str(i)] = error_activation\n",
        "    \n",
        "  return output_error_cache,activation_error_cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ19znQHh7PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_single_lstm_cell_error(activation_output_error,next_activation_error,\n",
        "                                     next_cell_error,parameters, lstm_activation, \n",
        "                                     cell_activation, prev_cell_activation):\n",
        "  \n",
        "  activation_error = activation_output_error + next_activation_error\n",
        "  \n",
        "  oa = lstm_activation['oa']\n",
        "  eo = np.multiply(activation_error, tanh_activation(cell_activation))\n",
        "  eo = np.multiply(np.multiply(eo,oa),1-oa)\n",
        "  \n",
        "  cell_error = np.multiply(activation_error,oa)\n",
        "  cell_error = np.multiply(cell_error, tanh_derivate(tanh_activation(cell_activation)))\n",
        "  cell_error += next_cell_error\n",
        "  \n",
        "  ia = lstm_activation['ia']\n",
        "  ga = lstm_activation['ga']\n",
        "  ei = np.multiply(cell_error, ga)\n",
        "  ei = np.multiply(np.multiply(ei, ia), 1-ia)\n",
        "  \n",
        "  eg = np.multiply(cell_error, ia)\n",
        "  eg = np.multiply(eg, tanh_derivative(ga))\n",
        "  \n",
        "  fa = lstm_activation['fa']\n",
        "  ef = np.multiply(cell_error, prev_cell_activation)\n",
        "  ef = np.multiply(np.multiply(ef, fa), 1-fa)\n",
        "  \n",
        "  prev_cell_error = np.multiply(cell_error, fa)\n",
        "  \n",
        "  fgw = parameters['fgw']\n",
        "  igw = parameters['igw']\n",
        "  ggw = parameters['ggw']\n",
        "  ogw = parameters['ogw']\n",
        "  \n",
        "  embed_activation_error = np.matmul(ef,fgw.T)\n",
        "  embed_activation_error = np.matmul(ei,igw.T)\n",
        "  embed_activation_error = np.matmul(eo,ogw.T)\n",
        "  embed_activation_error = np.matmul(eg,ggw.T)\n",
        "  \n",
        "  input_hidden_units = fgw.shape[0]\n",
        "  hidden_units = fgw.shape[1]\n",
        "  input_units = input_hidden_units - hidden_units\n",
        "  \n",
        "  prev_activation_error = embed_activation_error[:, :input_units]\n",
        "  \n",
        "  lstm_error = dict()\n",
        "  lstm_error['ef'] = ef\n",
        "  lstm_error['ei'] = ei\n",
        "  lstm_error['eo'] = eo\n",
        "  lstm_error['eg'] = eg\n",
        "  \n",
        "  return prev_activation_error, prev_cell_error, embed_error, lstm_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L3VJmJekRJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_output_cell_derivatives(output_error_cache, activation_cache, parameters):\n",
        "  dhow = np.zeros(parameters['how'].shape)\n",
        "  \n",
        "  batch_size = activation_cache['a1'].shape[0]\n",
        "  \n",
        "  for i in range(1, len(output_error_cache)+1):\n",
        "    \n",
        "    output_error = output_error_cache['eo' + str(i)]\n",
        "    \n",
        "    activation = activation_cache['a'+str(i)]\n",
        "    \n",
        "    dhow = np.matmul(activation.T, output_error) / batch_size\n",
        "    \n",
        "  return dhow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opt1D5erl701",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_single_lstm_cell_derivatives(lstm_error, embedding_matrix, activation_matrix):\n",
        "  ef = lstm_error['ef']\n",
        "  ei = lstm_error['ei']\n",
        "  eo = lstm_error['eo']\n",
        "  eg = lstm_error['eg']\n",
        "  \n",
        "  concat_matrix = np.concatenate((embedding_matrix, activation_matrix), axis=1)\n",
        "  \n",
        "  batch_size = embedding_matrix.shape[0]\n",
        "  \n",
        "  dfgw = np.matmul(concat_matrix.T, ef) / batch_size\n",
        "  digw = np.matmul(concat_matrix.T, ei) / batch_size\n",
        "  dogw = np.matmul(concat_matrix.T, eo) / batch_size\n",
        "  dggw = np.matmul(concat_matrix.T, eg) / batch_size\n",
        "  \n",
        "  derivatives = dict()\n",
        "  derivatives['dfgw'] = dfgw\n",
        "  derivatives['digw'] = digw\n",
        "  derivatives['dogw'] = dogw\n",
        "  derivatives['dggw'] = dggw\n",
        "  \n",
        "  return derivatives"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NceUL33m7yY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backward_propagation(batch_labels,embedding_cache,lstm_cache,activation_cache,cell_cache,output_cache,parameters):\n",
        "    output_error_cache,activation_error_cache = calculate_output_cell_error(batch_labels,output_cache,parameters)\n",
        "    \n",
        "    lstm_error_cache = dict()\n",
        "    \n",
        "    embedding_error_cache = dict()\n",
        "    \n",
        "    eat = np.zeros(activation_error_cache['ea1'].shape)\n",
        "    ect = np.zeros(activation_error_cache['ea1'].shape)\n",
        "    \n",
        "    for i in range(len(lstm_cache),0,-1):\n",
        "        pae,pce,ee,le = calculate_single_lstm_cell_error(activation_error_cache['ea'+str(i)],eat,ect,parameters,lstm_cache['lstm'+str(i)],cell_cache['c'+str(i)],cell_cache['c'+str(i-1)])\n",
        "        \n",
        "        lstm_error_cache['elstm'+str(i)] = le\n",
        "        \n",
        "        embedding_error_cache['eemb'+str(i-1)] = ee\n",
        "        \n",
        "        eat = pae\n",
        "        ect = pce\n",
        "    \n",
        "    \n",
        "    derivatives = dict()\n",
        "    derivatives['dhow'] = calculate_output_cell_derivatives(output_error_cache,activation_cache,parameters)\n",
        "    \n",
        "    lstm_derivatives = dict()\n",
        "    for i in range(1,len(lstm_error_cache)+1):\n",
        "        lstm_derivatives['dlstm'+str(i)] = calculate_single_lstm_cell_derivatives(lstm_error_cache['elstm'+str(i)],embedding_cache['emb'+str(i-1)],activation_cache['a'+str(i-1)])\n",
        "    \n",
        "    derivatives['dfgw'] = np.zeros(parameters['fgw'].shape)\n",
        "    derivatives['digw'] = np.zeros(parameters['igw'].shape)\n",
        "    derivatives['dogw'] = np.zeros(parameters['ogw'].shape)\n",
        "    derivatives['dggw'] = np.zeros(parameters['ggw'].shape)\n",
        "    \n",
        "    for i in range(1,len(lstm_error_cache)+1):\n",
        "        derivatives['dfgw'] += lstm_derivatives['dlstm'+str(i)]['dfgw']\n",
        "        derivatives['digw'] += lstm_derivatives['dlstm'+str(i)]['digw']\n",
        "        derivatives['dogw'] += lstm_derivatives['dlstm'+str(i)]['dogw']\n",
        "        derivatives['dggw'] += lstm_derivatives['dlstm'+str(i)]['dggw']\n",
        "    \n",
        "    return derivatives,embedding_error_cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETEk5VF7qjrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_parameters(parameters,derivatives,V,S,t):\n",
        "    dfgw = derivatives['dfgw']\n",
        "    digw = derivatives['digw']\n",
        "    dogw = derivatives['dogw']\n",
        "    dggw = derivatives['dggw']\n",
        "    dhow = derivatives['dhow']\n",
        "    \n",
        "    fgw = parameters['fgw']\n",
        "    igw = parameters['igw']\n",
        "    ogw = parameters['ogw']\n",
        "    ggw = parameters['ggw']\n",
        "    how = parameters['how']\n",
        "    \n",
        "    vfgw = V['vfgw']\n",
        "    vigw = V['vigw']\n",
        "    vogw = V['vogw']\n",
        "    vggw = V['vggw']\n",
        "    vhow = V['vhow']\n",
        "    \n",
        "    sfgw = S['sfgw']\n",
        "    sigw = S['sigw']\n",
        "    sogw = S['sogw']\n",
        "    sggw = S['sggw']\n",
        "    show = S['show']\n",
        "    \n",
        "    vfgw = (beta1*vfgw + (1-beta1)*dfgw)\n",
        "    vigw = (beta1*vigw + (1-beta1)*digw)\n",
        "    vogw = (beta1*vogw + (1-beta1)*dogw)\n",
        "    vggw = (beta1*vggw + (1-beta1)*dggw)\n",
        "    vhow = (beta1*vhow + (1-beta1)*dhow)\n",
        "    \n",
        "    sfgw = (beta2*sfgw + (1-beta2)*(dfgw**2))\n",
        "    sigw = (beta2*sigw + (1-beta2)*(digw**2))\n",
        "    sogw = (beta2*sogw + (1-beta2)*(dogw**2))\n",
        "    sggw = (beta2*sggw + (1-beta2)*(dggw**2))\n",
        "    show = (beta2*show + (1-beta2)*(dhow**2))\n",
        "    \n",
        "    fgw = fgw - learning_rate*((vfgw)/(np.sqrt(sfgw) + 1e-6))\n",
        "    igw = igw - learning_rate*((vigw)/(np.sqrt(sigw) + 1e-6))\n",
        "    ogw = ogw - learning_rate*((vogw)/(np.sqrt(sogw) + 1e-6))\n",
        "    ggw = ggw - learning_rate*((vggw)/(np.sqrt(sggw) + 1e-6))\n",
        "    how = how - learning_rate*((vhow)/(np.sqrt(show) + 1e-6))\n",
        "    \n",
        "    parameters['fgw'] = fgw\n",
        "    parameters['igw'] = igw\n",
        "    parameters['ogw'] = ogw\n",
        "    parameters['ggw'] = ggw\n",
        "    parameters['how'] = how\n",
        "    \n",
        "    V['vfgw'] = vfgw \n",
        "    V['vigw'] = vigw \n",
        "    V['vogw'] = vogw \n",
        "    V['vggw'] = vggw\n",
        "    V['vhow'] = vhow\n",
        "    \n",
        "    S['sfgw'] = sfgw \n",
        "    S['sigw'] = sigw \n",
        "    S['sogw'] = sogw \n",
        "    S['sggw'] = sggw\n",
        "    S['show'] = show\n",
        "    \n",
        "    return parameters,V,S    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRVPQGq8qr62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_embedding(embedings, embedding_error_cache, batch_labels):\n",
        "  embedding_derivatives = np.zeros(embeddings.shape)\n",
        "  \n",
        "  batch_size = batch_labels[0].shape[0]\n",
        "  \n",
        "  for i in range(len(embedding_error_cache)):\n",
        "    embedding_derivatives += np.matmul(batch_labels[i].T, embedding_error_cache['eemb'+str(i)])/batch_size\n",
        "  embeddings = embeddings - learning_rate*embedding_derivatives\n",
        "  return embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8GJKwT0rP9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_V(parameters):\n",
        "  Vfgw = np.zeros(parameters['fgw'].shape)\n",
        "  Vigw = np.zeros(parameters['igw'].shape)\n",
        "  Vogw = np.zeros(parameters['ogw'].shape)\n",
        "  Vggw = np.zeros(parameters['ggw'].shape)\n",
        "  Vhow = np.zeros(parameters['how'].shape)\n",
        "  \n",
        "  \n",
        "  V = dict()\n",
        "  V['vfgw'] = Vfgw\n",
        "  V['vigw'] = Vigw\n",
        "  V['vogw'] = Vogw\n",
        "  V['vggw'] = Vggw\n",
        "  V['vhow'] = Vhow\n",
        "  \n",
        "  return V\n",
        "\n",
        "def initialize_S(parameters):\n",
        "  Sfgw = np.zeros(parameters['fgw'].shape)\n",
        "  Sigw = np.zeros(parameters['igw'].shape)\n",
        "  Sogw = np.zeros(parameters['ogw'].shape)\n",
        "  Sggw = np.zeros(parameters['ggw'].shape)\n",
        "  Show = np.zeros(parameters['how'].shape)\n",
        "  \n",
        "  S = dict()\n",
        "  S['sfgw'] = Sfgw\n",
        "  S['sigw'] = Sigw\n",
        "  S['sogw'] = Sogw\n",
        "  S['sggw'] = Sggw\n",
        "  S['show'] = Show\n",
        "  \n",
        "  return S\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgoO8Wr4scKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_dataset, iters=1000, batch_size=20):\n",
        "  parameters = initialize_parameters()\n",
        "  \n",
        "  V = initialize_V(parameters)\n",
        "  S = initialize_S(parameters)\n",
        "  \n",
        "  embeddings = np.random.normal(0, 0.01, (len(vocab), input_units))\n",
        "  \n",
        "  J = []\n",
        "  P = []\n",
        "  A = []\n",
        "  \n",
        "  for step in range(iters):\n",
        "    index = step%len(train_dataset)\n",
        "    batches = train_dataset[index]\n",
        "    \n",
        "    embedding_cache,lstm_cache,activation_cache,cell_cache,output_cache = forward_propagation(batches, parameters, embeddings)\n",
        "    \n",
        "    perplexity, loss, acc = cal_loss_accuracy(batches, output_cache)\n",
        "    \n",
        "    derivatives, embedding, error_cache = backward_propagation(batches, embedding_cache, lstm_cache, activation_cache,cell_cache,output_cache,parameters)\n",
        "    \n",
        "    parameters, V, S = update_parameters(parameters, derivatives, V, S, step)\n",
        "    \n",
        "    embeddings = update_embeddings(embeddings, embedding_error_cache, batches)\n",
        "    \n",
        "    J.append(loss)\n",
        "    P.append(perplexity)\n",
        "    A.append(acc)\n",
        "    \n",
        "    if(step%1000==0):\n",
        "      print(\"For Single Batch :\")\n",
        "      print('Step       ={}'.format(step))\n",
        "      print('Loss       ={}'.format(round(loss,2)))\n",
        "      print('Perplexity ={}'.format(round(perplexity,2)))\n",
        "      print('Accuracy   ={}'.format(round(acc*100,2)))\n",
        "      print('\\n')\n",
        "    \n",
        "    return embeddings, parameters,J,P,A    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERw_iw8VuVlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings, parameters, J, P, A = train(train_dataset, iters=8001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDNv4OMoucMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss = list()\n",
        "avg_acc = list()\n",
        "avg_perp = list()\n",
        "i = 0\n",
        "while(i<len(J)):\n",
        "    avg_loss.append(np.mean(J[i:i+30]))\n",
        "    avg_acc.append(np.mean(A[i:i+30]))\n",
        "    avg_perp.append(np.mean(P[i:i+30]))\n",
        "    i += 30\n",
        "\n",
        "plt.plot(list(range(len(avg_loss))),avg_loss)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"Loss (Avg of 30 batches)\")\n",
        "plt.title(\"Loss Graph\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(list(range(len(avg_perp))),avg_perp)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"Perplexity (Avg of 30 batches)\")\n",
        "plt.title(\"Perplexity Graph\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(list(range(len(avg_acc))),avg_acc)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"Accuracy (Avg of 30 batches)\")\n",
        "plt.title(\"Accuracy Graph\")\n",
        "plt.show()    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmTR---bueWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(parameters,embeddings,id_char,vocab_size):\n",
        "    names = []\n",
        "    \n",
        "    for i in range(20):\n",
        "        a0 = np.zeros([1,hidden_units],dtype=np.float32)\n",
        "        c0 = np.zeros([1,hidden_units],dtype=np.float32)\n",
        "\n",
        "        name = ''\n",
        "        \n",
        "        batch_dataset = np.zeros([1,vocab_size])\n",
        "        \n",
        "        index = np.random.randint(0,27,1)[0]\n",
        "        \n",
        "        batch_dataset[0,index] = 1.0\n",
        "        \n",
        "        name += id_char[index]\n",
        "        \n",
        "        char = id_char[index]\n",
        "        \n",
        "        while(char!='.'):\n",
        "            batch_dataset = get_embeddings(batch_dataset,embeddings)\n",
        "\n",
        "            lstm_activations,ct,at = lstm_cell(batch_dataset,a0,c0,parameters)\n",
        "\n",
        "            ot = output_cell(at,parameters)\n",
        "            \n",
        "            pred = np.random.choice(27,1,p=ot[0])[0]\n",
        "                \n",
        "            name += id_char[pred]\n",
        "            \n",
        "            char = id_char[pred]\n",
        "            \n",
        "            batch_dataset = np.zeros([1,vocab_size])\n",
        "            batch_dataset[0,pred] = 1.0\n",
        "\n",
        "            a0 = at\n",
        "            c0 = ct\n",
        "            \n",
        "        names.append(name)\n",
        "        \n",
        "    return names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlFODBeWup_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(parameters,embeddings,id_char,vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YblSd2Gu49z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(parameters,embeddings,id_char,vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}